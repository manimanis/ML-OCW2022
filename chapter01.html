<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/css/bootstrap.min.css">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [
          ["\\(","\\)"],
          ['[mathjaxinline]','[/mathjaxinline]']
        ],
        displayMath: [
          ["\\[","\\]"],
          ['[mathjax]','[/mathjax]']
        ]
      }
    });
  </script>
  <script type="text/javascript">
    // Activating Mathjax accessibility files
    window.MathJax = {
      menuSettings: {
        collapsible: true,
        autocollapse: false,
        explorer: true
      }
    };
  </script>
  <script id="MathJax-script" async src="assets/MathJax/es5/tex-chtml-full.js"></script>
  <title>Chapter 1 : Introduction to ML</title>
</head>

<body>
  <main class="container">
    <h1>Introduction to ML</h1>
    <p>The main focus of machine learning is <i>making decisions</i> or <i>predictions</i> based on data.</p>
    <p>There are a number of other fields with significant overlap in technique, but difference in focus: in economics
      and psychology, the goal is to discover underlying causal processes and in statistics it is to find a model that
      fits a data set well.</p>
    <p>In those fields, the end product is a model. In machine learning, we often fit models, but as a mean to the end
      of
      making good predictions or decisions.</p>
    <p>As machine-learning (ML) methods have improved in their capability and scope, ML has become the best way,
      measured in terms of speed, human engineering time, and robustness, to make many applications. Great examples are
      face detection and speech recognition and many kinds of language-processing tasks. Almost any application that
      involves understanding data or signals that come from the real world can be best addressed using machine learning.
    </p>
    <p>One crucial aspect of machine learning approaches to solving problems is that human engineering plays an
      important role. A human still has to frame the problem:</p>
    <ul>
      <li>acquire and organize data,</li>
      <li>design a space of possible solutions,</li>
      <li>select a learning algorithm and its parameters,</li>
      <li>apply the algorithm to the data,</li>
      <li>validate the resulting solution to decide whether it's good enough to use,</li>
      <li>etc.</li>
    </ul>
    <p>The conceptual basis of learning from data is the problem of induction: <b>Why do we think that previously seen
        data will help us predict the future?</b> This is a serious philosophical problem of long standing.</p>
    <p>We will operationalize it by making assumptions, such as that all training data are IID (independent and
      identically distributed) and that queries will be drawn from the same distribution as the training data, or that
      the answer comes from a set of possible answers known in advance.</p>
    <p>In general, we need to solve these two problems:</p>
    <ul>
      <li><b>estimation:</b> When we have data that are noisy reflections of some underlying quantity of interest, we
        have to aggregate the data and make estimates or predictions about the quantity. How do we deal with the fact
        that, for example, the same treatment may end up with different results on different trials? How can we predict
        how well an estimate may compare to future results?</li>
      <li><b>generalization:</b> How can we predict results of a situation or experiment that we have never encountered
        before in our data set?</li>
    </ul>
    <p>We can describe problems and their solutions using six characteristics, three of which characterize the problem
      and three of which characterize the solution:
    </p>
    <ol>
      <li><b>Problem class:</b> What is the nature of the training data and what kinds of queries will be made at
        testing time?</li>
      <li><b>Assumptions:</b> What do we know about the source of the data or the form of the solution?</li>
      <li><b>Evaluation criteria:</b> What is the goal of the prediction or estimation system? How will the answers to
        individual queries be evaluated? How will the overall performance of the system be measured?</li>
      <li><b>Model type:</b> Will an intermediate model be made? What aspects of the data will be modeled? How will the
        model be used to make predictions?</li>
      <li><b>Model class:</b> What particular parametric class of models will be used? What criterion will we use to
        pick a particular model from the model class?</li>
      <li><b>Algorithm:</b> What computational process will be used to fit the model to the data and/or to make
        predictions?</li>
    </ol>
    <p>Without making some assumptions about the nature of the process generating the data, we cannot perform
      generalization. In the following sections, we elaborate on these ideas.</p>
  </main>

  <main class="container">
    <h1>Problem class</h1>
    <p>There are many different problem classes in machine learning. They vary according to what kind of data is
      provided and what kind of conclusions are to be drawn from it. Five standard problem classes are described below,
      to establish some notation and terminology.</p>

    <h2>Supervised learning</h2>
    <p>
      The idea of <em>supervised</em> learning is that the learning system is given inputs and told which specific
      outputs should be associated with them. We divide up supervised learning based on whether the outputs are drawn
      from a small finite set (classification) or a large finite or continuous set (regression). </p>

    <h3>Classification</h3>

    <p>Training data \( {\cal D}_ n \) is in the form of a set of pairs
      \( \{ (x^{(1)}, y^{(1)}), \ldots , (x^{(n)}, y^{(n)})\} \) where \( x^{(i)} \) represents an object to
      be classified, most typically a \( d \)-dimensional vector of real and/or discrete values, and \( y^{(i)} \) is an
      element of a
      discrete set of values. The \( y \) values are sometimes called <em>target values</em>.</p>
    <p>
      A classification problem is <em>binary</em> or <em>two-class</em> if \( y^{(i)} \) is drawn from a set of two
      possible values; otherwise, it is called <em>multi-class</em>.</p>
    <p>The goal in a classification problem is ultimately, given a new input value \( x^{(n+1)} \), to predict the value
      of \( y^{(n+1)} \).</p>
    <p>Classification problems are a kind of <em>supervised learning</em>, because the desired output (or class) \(
      y^{(i)} \) is specified for each of the training examples \( x^{(i)} \).</p>

    <h3>Regression</h3>
    <p>Regression is like classification, except that \( y^{(i)} \in \mathbb {R}^ k \).</p>

    <h2>Unsupervised learning</h2>

    <p><em>Unsupervised</em> learning doesn't involve learning a function from inputs to outputs based on a set of
      input-output pairs. Instead, one is given a data set and generally expected to find some patterns or structure
      inherent in it. </p>

    <h3>Density estimation</h3>
    <p>Given samples \( x^{(1)}, \ldots , x^{(n)} \in \mathbb {R}^ D \) drawn IID from some distribution \( \Pr (X) \),
      the goal is to predict the probability \( \Pr (x^{(n+1)}) \) of an element drawn from the same
      distribution. Density estimation sometimes plays a role as a “subroutine" in the overall learning method for
      supervised learning, as well.</p>

    <h3>Clustering</h3>
    <p>Given samples \( x^{(1)}, \ldots , x^{(n)} \in \mathbb {R}^ D\), the goal is
      to find a partitioning (or “clustering") of the samples that groups together samples that are similar. There are
      many different objectives, depending on the definition of the similarity between samples and exactly what
      criterion is to be used (e.g., minimize the average distance between elements inside a cluster and maximize the
      average distance between elements across clusters). Other methods perform a “soft" clustering, in which samples
      may be assigned 0.9 membership in one cluster and 0.1 in another. Clustering is sometimes used as a step in
      density estimation, and sometimes to find useful structure in data.
    </p>

    <h3>Dimensionality reduction</h3>
    <p>Given samples \( x^{(1)}, \ldots , x^{(n)} \in \mathbb {R}^ D \), the problem
      is to re-represent them as points in a \( d\)-dimensional space, where \( d &lt; D \). The goal is typically to
      retain information in the data set that will, e.g., allow elements of one class to be discriminated from
      another. </p>
    <p>Dimensionality reduction is a standard technique which is particularly useful for visualizing or understanding
      high-dimensional data. If the goal is ultimately to perform regression or classification on the data after the
      dimensionality is reduced, it is usually best to articulate an objective for the overall prediction problem
      rather than to first do dimensionality reduction without knowing which dimensions will be important for the
      prediction task. </p>

    <h4>Reinforcement learning</h4>
    <p>In reinforcement learning, the goal is to learn a mapping from input values \( x \) to output values \( y \), but
      without a direct supervision signal to specify which output values \( y \) are best for a particular input. There
      is no training set specified <em>a priori</em>. Instead, the learning problem is framed as an agent interacting
      with an environment, in the following setting:
    </p>
    <ul>
      <li>The agent observes the current state, \( x^{(0)} \).</li>
      <li>It selects an action, \( y^{(0)} \).</li>
      <li>It receives a reward, \( r^{(0)} \), which depends on \( x^{(0)} \) and possibly \( y^{(0)} \).</li>
      <li>The environment transitions probabilistically to a new state, \( x^{(1)} \), with a distribution that depends
        only on \( x^{(0)} \) and \( y^{(0)} \).</li>
      <li>The agent observes the current state, \( x^{(1)} \).</li>
      <li>\( \ldots \)</li>
    </ul>
    <p>The goal is to find a policy \( \pi \), mapping \( x \) to \( y \), (that is, states to actions) such that some
      long-term sum or average of rewards \( r \) is maximized.
    </p>
    <p>This setting is very different from either supervised learning or unsupervised learning, because the agent's
      action choices affect both its reward and its ability to observe the environment. It requires careful
      consideration of the long-term effects of actions, as well as all of the other issues that pertain to supervised
      learning. </p>

    <h3>Other settings</h3>
    <p>There are many other problem settings. Here are a few.</p>
    <p>In <em>semi-supervised</em> learning, we have a supervised-learning training set, but there may be an additional
      set of \( x^{(i)} \) values with no known \( y^{(i)} \). These values can still be used to improve
      learning performance if they are drawn from \( \Pr (X) \) that is the marginal of \( \Pr (X, Y) \) that governs
      the rest of the data set.
    </p>
    <p>In <em>active</em> learning, it is assumed to be expensive to acquire a label \( y^{(i)} \) (imagine asking a
      human to read an x-ray image), so the learning algorithm can sequentially ask for particular inputs \( x^{(i)} \)
      to be labeled, and must carefully select queries in order to learn as effectively as possible while minimizing the
      cost of labeling.</p>
    <p>In <em>transfer</em> learning (also called <em>meta-learning</em>), there are multiple tasks, with data drawn
      from different, but related, distributions. The goal is for experience with previous tasks to apply to learning a
      current task in a way that requires decreased experience with the new task. </p>
  </main>

  <main class="container">
    <h1>Assumptions</h1>

    <p>The kinds of assumptions that we can make about the data source or the solution include:</p>
    <ul>
      <li>The data are independent and identically distributed.</li>
      <li>The data are generated by a Markov chain.</li>
      <li>The process generating the data might be adversarial.</li>
      <li>The “true" model that is generating the data can be perfectly described by one of some particular set of
        hypotheses.</li>
    </ul>
  </main>

  <main class="container">
    <h1>Evaluation criteria</h1>

    <p>Once we have specified a problem class, we need to say what makes an output or the answer to a query good, given
      the training data. We specify evaluation criteria at two levels: how an individual prediction is scored, and how
      the overall behavior of the prediction or estimation system is scored.</p>
    <p>The quality of predictions from a learned model is often expressed in terms of a <em>loss function</em>. A loss
      function \( L(g, a) \) tells you how much you will be penalized for making a guess \( g \) when the answer is
      actually \( a \). There are many possible loss functions. Here are some frequently used examples:</p>
    <ul>
      <li><b>0-1 Loss</b> applies to predictions drawn from finite domains.
        <p>\( L(g, a) = \begin{cases} 0 & \text {if $g = a$} \\ 1 & \text {otherwise} \end{cases} \)</p>
      </li>
      <li>
        <b class="bf">Squared loss</b>
        <p>\( L(g, a) = (g - a)^2 \)</p>
      </li>
      <li>
        <b class="bf">Linear loss</b>
        <p>\( L(g, a) = |g - a| \)</p>
      </li>
      <li>
        <b class="bf">Asymmetric loss</b> Consider a situation in which you are trying to predict whether someone is
        having a heart attack. It might be much worse to predict “no" when the answer is really “yes", than the other
        way around.
        <p>\( L(g, a) = \begin{cases} 1 & \text {if $g = 1$ and $a = 0$} \\ 10 & \text {if $g = 0$ and $a = 1$} \\ 0 &
          \text {otherwise} \end{cases} \)</p>
        <p>Any given prediction rule will usually be evaluated based on multiple predictions and the loss of each one.
          At this level, we might be interested in: </p>
        <ul>
          <li>Minimizing expected loss over all the predictions (also known as risk)</li>
          <li>Minimizing maximum loss: the loss of the worst prediction</li>
          <li>Minimizing or bounding regret: how much worse this predictor performs than the best one drawn from some
            class</li>
          <li>Characterizing asymptotic behavior: how well the predictor will perform in the limit of infinite training
            data</li>
          <li>Finding algorithms that are probably approximately correct: they probably generate a hypothesis that is
            right most of the time.</li>
        </ul>
        <p>
          There is a theory of rational agency that argues that you should always select the action that <em>minimizes
            the expected loss</em>. This strategy will, for example, make you the most money in the long run, in a
          gambling setting. Expected loss is also sometimes called <em>risk</em> in the machine-learning literature, but
          that term means other things in economics or other parts of decision theory, so be careful...it's risky to use
          it. We will, most of the time, concentrate on this criterion.</p>
      </li>
    </ul>
  </main>

  <main class="container">
    <h1>Model type</h1>

    <p>Recall that the goal of a machine-learning system is typically to estimate or generalize, based on data provided.
      Below, we examine the role of model-making in machine learning.</p>

    <h2>No model</h2>
    <p>In some simple cases, in response to queries, we can generate predictions directly from the training data,
      without the construction of any intermediate model. For example, in regression or classification, we might
      generate an answer to a new query by averaging answers to recent queries, as in the <em>nearest neighbor</em>
      method.</p>

    <h2>Prediction rule</h2>
    <p>This two-step process is more typical: </p>
    <ol>
      <li>“Fit" a model to the training data</li>
      <li>Use the model directly to make predictions</li>
    </ol>

    <p>In the <em>prediction rule</em> setting of regression or classification, the model will be some hypothesis or
      prediction rule \( y = h(x ; \theta ) \) for some functional form \( h \). The idea is that \( \theta \) is a
      vector of one or more parameter values that will be determined by fitting the model to the training data and then
      be held fixed. Given a new \( x^{(n+1)} \), we would then make the prediction \( h(x^{(n+1)}; \theta ) \).
    </p>
    <p>The fitting process is often articulated as an optimization problem: Find a value of \( \theta \) that minimizes
      some criterion involving \( \theta \) and the data. An optimal strategy, if we knew the actual underlying
      distribution on our data, \( \Pr (X,Y) \) would be to predict the value of \( y \) that minimizes the <em>expected
        loss</em>, which is also known as the <em>test error</em>. If we don't have that actual underlying distribution,
      or even an estimate of it, we can take the approach of minimizing the <em>training error</em>: that is, finding
      the prediction rule \( h \) that minimizes the average loss on our training data set. So, we would seek \( \theta
      \) that minimizes</p>
    <p style="text-align: center;">\( \mathcal{E}_ n(\theta ) = \frac{1}{n}\sum _{i = 1}^ n L(h(x^{(i)};\theta ),
      y^{(i)})\; \; , \)</p>
    <p>where the loss function \( L(g, a) \) measures how bad it would be to make a guess of \( g \) when the actual
      value is \( a \).</p>
    <p>We will find that minimizing training error alone is often not a good choice: it is possible to emphasize fitting
      the current data too strongly and end up with a hypothesis that does not generalize well when presented with new
      \( x \) values.
    </p>
  </main>

  <main class="container">
    <h1>Model class and parameter fitting</h1>

    <p>A model <em>class</em> \( {\cal M} \) is a set of possible models, typically parameterized by a vector of
      parameters \( \Theta \). What assumptions will we make about the form of the model? When solving a regression
      problem using a prediction-rule approach, we might try to find a linear function \( h(x ; \theta , \theta _0) =
      \theta ^ T x + \theta _0 \) that fits our data well. In this example, the parameter vector \( \Theta = (\theta ,
      \theta _0) \).
    </p>
    <p>For problem types such as discrimination and classification, there are huge numbers of model classes that have
      been considered... We'll spend much of this course exploring these model classes, especially neural networks
      models. We will almost completely restrict our attention to model classes with a fixed, finite number of
      parameters. Models that relax this assumption are called “non-parametric" models.</p>
    <p>How do we select a model class? In some cases, the machine-learning practitioner will have a good idea of what an
      appropriate model class is, and will specify it directly. In other cases, we may consider several model classes.
      In such situations, we are solving a <em>model selection</em> problem: model-selection is to pick a model class
      \( {\cal M} \) from a (usually finite) set of possible model classes; <em>model fitting</em> is to pick a
      particular model in that class, specified by parameters \( \theta \).</p>
  </main>

  <main class="container">
    <h1>Algorithm</h1>

    <p>Once we have described a class of models and a way of scoring a model given data, we have an algorithmic problem:
      what sequence of computational instructions should we run in order to find a good model from our class? For
      example, determining the parameter vector \( \theta \) which minimizes \( \mathcal{E}_ n(\theta ) \) might be done
      using a familiar least-squares minimization algorithm, when the model \( h \) is a function being fit to some data
      \( x \).</p>
    <p>Sometimes we can use software that was designed, generically, to perform optimization. In many other cases, we
      use algorithms that are specialized for machine-learning problems, or for particular hypotheses classes. </p>
    <p>Some algorithms are not easily seen as trying to optimize a particular criterion. In fact, the first algorithm we
      study for finding linear classifiers, the perceptron algorithm, has this character.</p>
  </main>

  <script src="assets/js/bootstrap.bundle.min.js"></script>
</body>

</html>